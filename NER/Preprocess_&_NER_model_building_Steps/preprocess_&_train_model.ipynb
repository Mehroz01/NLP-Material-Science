{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os.path\n",
    "import spacy\n",
    "from os import listdir\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import BytesIO\n",
    "from __future__ import unicode_literals, print_function\n",
    "from spacy.lang.en import English\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr,  laparams=laparams)#codec=codec,\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "    \n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_str=r\"nitric acid mass lost test (NAMLT)|NAMLT|ASTM G67-04|ASTM|VMP3|EC-Lab|electrode|saturated calomel electrode (SCE)|SCE|platinum mesh|potentiodynamic polarisation|Tafel extrapolation|Eclab|polarisation test|Hardness tests|CALPHAD|A300 device|PanPhaseDiagram|Pandat|backscattered electron images (BSE)|BSE|JEOL|gun-scanning|microscopy|X-ray|EDS|electron backscatter diffraction (EBSD)|EBSD|3D FEG|FEI Quanta|PECS|precision etching coating system (PECS TM )|precision etching coating system|transmission electron microscopy|Gatan precision ion polishing system|JMP|inductively coupled plasma atomic emission spectroscopy|transmission electron microscopy (TEM)|TEM|ICP-AES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #file_path='/home/mehroz/pdf_filed_2/Untitled Folder/Aluminum paper/1-s2.0-S135964541630828X-main.pdf'\n",
    "# path='/home/mehroz/pdf_filed_2/Untitled Folder/Aluminum paper/'\n",
    "\n",
    "def preprocess(path):\n",
    "    \n",
    "\n",
    "                \n",
    "                \n",
    "    nlp = spacy.load(\"en\")\n",
    "    regex_str=r\"nitric acid mass lost test (NAMLT)|NAMLT|ASTM G67-04|ASTM|VMP3|EC-Lab|electrode|saturated calomel electrode (SCE)|SCE|platinum mesh|potentiodynamic polarisation|Tafel extrapolation|Eclab|polarisation test|Hardness tests|CALPHAD|A300 device|PanPhaseDiagram|Pandat|backscattered electron images (BSE)|BSE|JEOL|gun-scanning|microscopy|X-ray|EDS|electron backscatter diffraction (EBSD)|EBSD|3D FEG|FEI Quanta|PECS|precision etching coating system (PECS TM )|precision etching coating system|transmission electron microscopy|Gatan precision ion polishing system|JMP|inductively coupled plasma atomic emission spectroscopy|transmission electron microscopy (TEM)|TEM|ICP-AES\"\n",
    "    sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "    nlp.add_pipe(sentencizer,first=True)#\n",
    "    pdf_files=listdir(path)\n",
    "    compositions_list=[]\n",
    "    \n",
    "    \n",
    "            \n",
    "#     for indx in range(0,len(partial_list)):\n",
    "#         remaining_sent=partial_list[indx]\n",
    "#         x1 = re.finditer(partial_regex,remaining_sent)\n",
    "#         if x1:\n",
    "            \n",
    "#             for match_data in x1:\n",
    "#                 result=match_data.span()\n",
    "#                 print('\\n remaining matched->',remaining_sent[result[0]:result[1]])\n",
    "#                 #print('\\n',sentence[result[0]:result[1]],'<-sentence-> ',sentence)\n",
    "#                 r1=(remaining_sent.decode(\"utf-8\"),{\"entities\":[(remaining_sent[0],remaining_sent[1],\"Composition\")]})\n",
    "#                 #print('\\n r type :',type(r))\n",
    "#                 compositions_list.append(r1)\n",
    "                \n",
    "    for pdf_file_index in range(0,len(pdf_files)):\n",
    "        pdf_file_path=path+pdf_files[pdf_file_index]\n",
    "        print('\\n Address :',pdf_file_path)\n",
    "        \n",
    "        text_file=convert_pdf_to_txt(pdf_file_path)\n",
    "        doc = nlp(text_file)\n",
    "        \n",
    "        for sent in doc.sents:\n",
    "            #print('\\n ----- ',sent)\n",
    "            #print('\\n --- ',str(sent))\n",
    "            #print('\\n type :',type(sent))\n",
    "            sentence=str(sent)\n",
    "            x = re.finditer(regex_str,sentence)\n",
    "            if x:\n",
    "                #print('\\n ----- ',sent)\n",
    "                entity=\"entities\"\n",
    "                #entity=entity.encode(\"utf-8\")\n",
    "                category=\"method\"\n",
    "                #product=product.decode(\"utf-8\")\n",
    "                \n",
    "                for match in x:\n",
    "                    result=match.span()\n",
    "                    print('\\n matched->',sentence[result[0]:result[1]])\n",
    "                    print('\\n',sentence[result[0]:result[1]],'<-sentence-> ',sentence)\n",
    "                    r=(sentence,{entity:[(result[0],result[1],category)]})\n",
    "                    #print('\\n r type :',type(r))\n",
    "                    compositions_list.append(r)\n",
    "                    \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    return compositions_list                    \n",
    "        #get_compositions(text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_spacy(data,iterations):\n",
    "    TRAIN_DATA = data\n",
    "    spacy.prefer_gpu()\n",
    "    spacy.require_gpu()\n",
    "    \n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "       \n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                print('\\n Text is ',text)\n",
    "                print('\\n annotation is ',annotations)\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.3,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print('\\n loses ',losses)\n",
    "    return nlp\n",
    "iterations=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #path='/home/mehroz/pdf_filed_2/Untitled Folder/Aluminum paper/'\n",
    "# #path='/home/mehroz/pdf_filed_2/Untitled_Folder/train_model/'\n",
    "path='/home/cloud4/Mehroz/Mat_Sci/train_data/'\n",
    "\n",
    "#compositions=preprocess(path)\n",
    "#print(len(compositions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3172\n",
      "\n",
      " done\n"
     ]
    }
   ],
   "source": [
    "print(len(compositions))\n",
    "print('\\n done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=10\n",
    "#spacy.prefer_gpu()\n",
    "#prdnlp=train_spacy(compositions,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Save our trained Model\n",
    "# modelfile = \"Methods_GPU_model_0.1\"\n",
    "# prdnlp.to_disk(modelfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_model = spacy.load(\"Methods_GPU_model_0.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : NAMLT\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : ICP-AES\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : ASTM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : NAMLT\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : VMP3\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : electrode\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : Tafel extrapolation\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : CALPHAD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : Pandat\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : PanPhaseDiagram\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : BSE\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : JEOL\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : X-ray\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : PECS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : transmission electron microscopy\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : JMP\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : BSE\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : CALPHAD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : BSE\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : BSE\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EBSD\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : yNd\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : saturated\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : >\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : TEM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : EDS\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : NAMLT\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : JOM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : 73\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : 33\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : 70\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : ASTM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : NAMLT\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : ASTM\n",
      "\n",
      " ==end==\n",
      "\n",
      " ==Start==\n",
      "\n",
      " Method : 52\n",
      "\n",
      " ==end==\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "#nlp = spacy.load(\"test_model\")\n",
    "file_path='../one_paper_test/1-s2.0-S0010938X18319164-main.pdf'\n",
    "test_text_file=convert_pdf_to_txt(file_path)\n",
    "\n",
    "method\n",
    "doc = nlp(test_text_file)\n",
    "for sent in doc.sents:\n",
    "    sentence=sent.text\n",
    "    doc_processes = process_model(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    print('testing')\n",
    "    for ent in doc_processes.ents:\n",
    "        print('\\n ==Start==')\n",
    "        print('\\n Method :',ent.text)\n",
    "        #print('\\n sentence :',sent)\n",
    "        print('\\n ==end==')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
